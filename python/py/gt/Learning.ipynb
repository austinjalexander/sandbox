{
 "metadata": {
  "name": "",
  "signature": "sha256:375fbf9cb5637eabea8a45a3c8b1999adeeca8824b8301133473a8c9b63f1a0a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Supervised"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "instances (input)  \n",
      "concept (function/mapper)  \n",
      "target (answer)  \n",
      "hypothesis (class)  \n",
      "sample (training set)  \n",
      "candidate (concept $\\stackrel{?}{=}$ target)  \n",
      "testing set  \n",
      "\n",
      "generalization, not memorization, is the whole point of machine learning"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Unsupervised"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from scipy import optimize as op"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.arange(1,101)\n",
      "def f(x):\n",
      "    return (x % 6)**2 % 7 - np.sin(x)\n",
      "\n",
      "y = f(X)\n",
      "max_y = max(y)\n",
      "for x in X:\n",
      "    if f(x) == max_y:\n",
      "        print x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "11\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print [x % 6 for x in X]\n",
      "print 25 % 7"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4]\n",
        "4\n"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "random restart hillclimbing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = [0.14,0.36,0.21,0.29]\n",
      "from matplotlib import pyplot as plt\n",
      "%matplotlib inline\n",
      "plt.hist()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEACAYAAACwB81wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x112a36210>"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Reinforcement"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Markov Decision Processes\n",
      "\n",
      "definition of problem:  \n",
      "States: $S$ (set; things taht describe the world)  \n",
      "Model: $T(s, a, s') \\sim Pr(s'|s,a)$ (describes rules/physics of world/game; function of state, action, and another state; produces probability; transition function)  \n",
      "Actions: $A(s), A$ (things that can be done in a state; a function of state)  \n",
      "Reward: $R(s), R(s,a), R(s,a,s')$ (scalar value for being in a state; encompasses the domain knowledge; different reward types)  \n",
      "\n",
      "these four things define a MDP\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Markovian property: only the present matters; memoryless; only depends on current state $s$, rules don't change (i.e., stationary)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "definition of solution:  \n",
      "Policy: $\\pi(s) \\rightarrow a$ (function that takes in a state, returns action)  \n",
      "$\\pi*$ policy that maximizes/optimizes long term reward\n",
      "\n",
      "you can refer a plan, but it's technically not working on a plan (since only one state/action at a time)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "delayed reward (don't know how each step affects reward until the end)  \n",
      "minor changes matter  \n",
      "The (Temporal) Credit Assignment Problem  "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}