{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from time import time\n",
    "import pickle\n",
    "sys.path.append(\"ud120-projects/tools/\")\n",
    "sys.path.append(\"ud120-projects/final_project/\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import test_classifier, dump_classifier_and_data\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Load the dictionary containing the dataset\n",
    "data_dict = pickle.load(open(\"ud120-projects/final_project/final_project_dataset.pkl\", \"r\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "\tAccuracy: 0.25560\tPrecision: 0.18481\tRecall: 0.79800\tF1: 0.30011\tF2: 0.47968\n",
      "\tTotal predictions: 10000\tTrue positives: 1596\tFalse positives: 7040\tFalse negatives:  404\tTrue negatives:  960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "features_list = ['poi','salary'] # You will need to use more features\n",
    "\n",
    "### Task 2: Remove outliers\n",
    "### Task 3: Create new feature(s)\n",
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n",
    "\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "clf = GaussianNB()    # Provided to give you a starting point. Try a varity of classifiers.\n",
    "\n",
    "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
    "### using our testing script.\n",
    "### Because of the small size of the dataset, the script uses stratified\n",
    "### shuffle split cross validation. For more info: \n",
    "### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
    "\n",
    "test_classifier(clf, my_dataset, features_list)\n",
    "\n",
    "### Dump your classifier, dataset, and features_list so \n",
    "### anyone can run/check your results.\n",
    "\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METTS MARK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bonus': 600000,\n",
       " 'deferral_payments': 'NaN',\n",
       " 'deferred_income': 'NaN',\n",
       " 'director_fees': 'NaN',\n",
       " 'email_address': 'mark.metts@enron.com',\n",
       " 'exercised_stock_options': 'NaN',\n",
       " 'expenses': 94299,\n",
       " 'from_messages': 29,\n",
       " 'from_poi_to_this_person': 38,\n",
       " 'from_this_person_to_poi': 1,\n",
       " 'loan_advances': 'NaN',\n",
       " 'long_term_incentive': 'NaN',\n",
       " 'other': 1740,\n",
       " 'poi': False,\n",
       " 'restricted_stock': 585062,\n",
       " 'restricted_stock_deferred': 'NaN',\n",
       " 'salary': 365788,\n",
       " 'shared_receipt_with_poi': 702,\n",
       " 'to_messages': 807,\n",
       " 'total_payments': 1061827,\n",
       " 'total_stock_value': 585062}"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print my_dataset.keys()[0]\n",
    "my_dataset.itervalues().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['poi', 'salary']"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146,) ['METTS MARK' 'BAXTER JOHN C' 'ELLIOTT STEVEN' 'CORDES WILLIAM R'\n",
      " 'HANNON KEVIN P'] \n",
      "\n",
      "['poi', 'bonus', 'deferral_payments', 'deferred_income', 'director_fees', 'exercised_stock_options', 'expenses', 'from_messages', 'from_poi_to_this_person', 'from_this_person_to_poi', 'loan_advances', 'long_term_incentive', 'other', 'restricted_stock', 'restricted_stock_deferred', 'salary', 'shared_receipt_with_poi', 'to_messages', 'total_payments', 'total_stock_value']\n"
     ]
    }
   ],
   "source": [
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "\n",
    "names = np.array(my_dataset.keys())\n",
    "print names.shape, names[:5], \"\\n\"\n",
    "features_list = my_dataset.itervalues().next().keys()\n",
    "features_list.sort()\n",
    "features_list.remove('poi')\n",
    "features_list.insert(0, 'poi')\n",
    "features_list.remove('email_address')\n",
    "print features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POI Count:\n",
      "0    128\n",
      "1     18\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poi</th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>other</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94299</td>\n",
       "      <td>29</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1740</td>\n",
       "      <td>585062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>365788</td>\n",
       "      <td>702</td>\n",
       "      <td>807</td>\n",
       "      <td>1061827</td>\n",
       "      <td>585062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1200000</td>\n",
       "      <td>1295738</td>\n",
       "      <td>-1386055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6680544</td>\n",
       "      <td>11200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1586055</td>\n",
       "      <td>2660303</td>\n",
       "      <td>3942714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>267102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5634343</td>\n",
       "      <td>10623258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>350000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-400729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4890344</td>\n",
       "      <td>78552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12961</td>\n",
       "      <td>1788391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211725</td>\n",
       "      <td>6678735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>651850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>386335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1038185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3117011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5538001</td>\n",
       "      <td>34039</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1617011</td>\n",
       "      <td>11350</td>\n",
       "      <td>853064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>243293</td>\n",
       "      <td>1035</td>\n",
       "      <td>1045</td>\n",
       "      <td>288682</td>\n",
       "      <td>6391065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   poi    bonus  deferral_payments  deferred_income  director_fees  \\\n",
       "0    0   600000                NaN              NaN            NaN   \n",
       "1    0  1200000            1295738         -1386055            NaN   \n",
       "2    0   350000                NaN          -400729            NaN   \n",
       "3    0      NaN                NaN              NaN            NaN   \n",
       "4    1  1500000                NaN         -3117011            NaN   \n",
       "\n",
       "   exercised_stock_options  expenses  from_messages  from_poi_to_this_person  \\\n",
       "0                      NaN     94299             29                       38   \n",
       "1                  6680544     11200            NaN                      NaN   \n",
       "2                  4890344     78552            NaN                      NaN   \n",
       "3                   651850       NaN             12                       10   \n",
       "4                  5538001     34039             32                       32   \n",
       "\n",
       "   from_this_person_to_poi  loan_advances  long_term_incentive    other  \\\n",
       "0                        1            NaN                  NaN     1740   \n",
       "1                      NaN            NaN              1586055  2660303   \n",
       "2                      NaN            NaN                  NaN    12961   \n",
       "3                        0            NaN                  NaN      NaN   \n",
       "4                       21            NaN              1617011    11350   \n",
       "\n",
       "   restricted_stock  restricted_stock_deferred  salary  \\\n",
       "0            585062                        NaN  365788   \n",
       "1           3942714                        NaN  267102   \n",
       "2           1788391                        NaN  170941   \n",
       "3            386335                        NaN     NaN   \n",
       "4            853064                        NaN  243293   \n",
       "\n",
       "   shared_receipt_with_poi  to_messages  total_payments  total_stock_value  \n",
       "0                      702          807         1061827             585062  \n",
       "1                      NaN          NaN         5634343           10623258  \n",
       "2                      NaN          NaN          211725            6678735  \n",
       "3                       58          764             NaN            1038185  \n",
       "4                     1035         1045          288682            6391065  "
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### convert dictionary to pandas dataframe\n",
    "\n",
    "df = pd.DataFrame([entry for entry in my_dataset.itervalues()])\n",
    "df = df.drop('email_address', axis=1)\n",
    "df = df[features_list]\n",
    "#df.dtypes\n",
    "#df.describe()\n",
    "#df.count()\n",
    "df.poi = df.poi.astype('int')\n",
    "df = df.convert_objects(convert_numeric=True)\n",
    "\n",
    "for col in list(df.columns):\n",
    "    df[col] = df[col].round(decimals=3)\n",
    "    \n",
    "print \"POI Count:\\n\", df.poi.value_counts()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146,)\n",
      "[0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# create labels\n",
    "y = df.poi.values\n",
    "print y.shape\n",
    "print y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 19)\n"
     ]
    }
   ],
   "source": [
    "# create initial features\n",
    "X = df.drop('poi', axis=1).values\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.00000000e+05   1.64267415e+06  -1.14047514e+06   1.66804882e+05\n",
      "    5.98705377e+06   9.42990000e+04   2.90000000e+01   3.80000000e+01\n",
      "    1.00000000e+00   4.19625000e+07   1.47036145e+06   1.74000000e+03\n",
      "    5.85062000e+05   1.66410556e+05   3.65788000e+05   7.02000000e+02\n",
      "    8.07000000e+02   1.06182700e+06   5.85062000e+05]\n",
      " [  1.20000000e+06   1.29573800e+06  -1.38605500e+06   1.66804882e+05\n",
      "    6.68054400e+06   1.12000000e+04   6.08790698e+02   6.48953488e+01\n",
      "    4.12325581e+01   4.19625000e+07   1.58605500e+06   2.66030300e+06\n",
      "    3.94271400e+06   1.66410556e+05   2.67102000e+05   1.17646512e+03\n",
      "    2.07386047e+03   5.63434300e+06   1.06232580e+07]\n",
      " [  3.50000000e+05   1.64267415e+06  -4.00729000e+05   1.66804882e+05\n",
      "    4.89034400e+06   7.85520000e+04   6.08790698e+02   6.48953488e+01\n",
      "    4.12325581e+01   4.19625000e+07   1.47036145e+06   1.29610000e+04\n",
      "    1.78839100e+06   1.66410556e+05   1.70941000e+05   1.17646512e+03\n",
      "    2.07386047e+03   2.11725000e+05   6.67873500e+06]\n",
      " [  2.37423461e+06   1.64267415e+06  -1.14047514e+06   1.66804882e+05\n",
      "    6.51850000e+05   1.08728916e+05   1.20000000e+01   1.00000000e+01\n",
      "    0.00000000e+00   4.19625000e+07   1.47036145e+06   9.19064968e+05\n",
      "    3.86335000e+05   1.66410556e+05   5.62194295e+05   5.80000000e+01\n",
      "    7.64000000e+02   5.08152649e+06   1.03818500e+06]\n",
      " [  1.50000000e+06   1.64267415e+06  -3.11701100e+06   1.66804882e+05\n",
      "    5.53800100e+06   3.40390000e+04   3.20000000e+01   3.20000000e+01\n",
      "    2.10000000e+01   4.19625000e+07   1.61701100e+06   1.13500000e+04\n",
      "    8.53064000e+05   1.66410556e+05   2.43293000e+05   1.03500000e+03\n",
      "    1.04500000e+03   2.88682000e+05   6.39106500e+06]]\n"
     ]
    }
   ],
   "source": [
    "# imputation for 'NaN' values\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(X)\n",
    "X = imp.transform(X)\n",
    "print X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names associated with outlier-containing rows to remove:\n",
      "\tMENDELSOHN JOHN\n",
      "\tPICKERING MARK R\n",
      "\tFOY JOE\n",
      "\tTOTAL\n",
      "\tDELAINEY DAVID W\n",
      "\tLAVORATO JOHN J\n",
      "\tBOWEN JR RAYMOND M\n",
      "\tBANNANTINE JAMES M\n",
      "\tBELDEN TIMOTHY N\n",
      "\tSHAPIRO RICHARD S\n",
      "\tWALLS JR ROBERT H\n",
      "\tBHATNAGAR SANJAY\n",
      "\tBELFER ROBERT\n",
      "\tKAMINSKI WINCENTY J\n",
      "\tDODSON KEITH\n",
      "\tHICKERSON GARY J\n",
      "\n",
      "new X shape:  (130, 19)\n",
      "\n",
      "total rows removed:  16 (0.11)\n"
     ]
    }
   ],
   "source": [
    "### Task 2: Remove outliers\n",
    "num_rows = X.shape[0]\n",
    "num_cols = X.shape[1]\n",
    "rows_to_remove = set()\n",
    "\n",
    "for i in xrange(num_cols):\n",
    "    point_five_percentile = np.percentile(X[:,i], 0.5)\n",
    "    ninety_nine_point_five_percentile = np.percentile(X[:,i], 99.5)\n",
    "    \n",
    "    for j in xrange(num_rows):\n",
    "        if X[j,i] < point_five_percentile:\n",
    "            #print \"\\tlow outlier: \", \"row: \", j, \"col: \", i, \" -> \", X[j,i]\n",
    "            rows_to_remove.add(j)\n",
    "        elif X[j,i] > ninety_nine_point_five_percentile:\n",
    "            #print \"\\thigh outlier: \", \"row: \", j, \"col: \", i, \" -> \", X[j,i]\n",
    "            rows_to_remove.add(j)\n",
    "\n",
    "X = np.delete(X, list(rows_to_remove), axis=0)\n",
    "y = np.delete(y, list(rows_to_remove))\n",
    "\n",
    "print \"names associated with outlier-containing rows to remove:\"\n",
    "for i in rows_to_remove:\n",
    "    print \"\\t\",names[i]\n",
    "    \n",
    "names = np.delete(names, list(rows_to_remove))\n",
    "\n",
    "print \"\\nnew X shape: \", X.shape\n",
    "print \"\\ntotal rows removed: \", len(rows_to_remove), \"({})\".format(round(len(rows_to_remove)/float(num_rows), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117, 19) (13, 19) (117,) (13,)\n"
     ]
    }
   ],
   "source": [
    "# split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "print X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117, 19)\n",
      "(13, 19)\n"
     ]
    }
   ],
   "source": [
    "### Task 3: Create new feature(s)\n",
    "# scale\n",
    "scaler = MinMaxScaler()\n",
    "scaler = scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "print X_train.shape\n",
    "X_test = scaler.transform(X_test)\n",
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.02898551e-01,   2.54666734e-01,   1.10572927e-01, ...,\n",
       "          7.77410208e-02,   2.77527157e-03,   1.29298865e-01],\n",
       "       [  3.29599219e-01,   2.54666734e-01,   9.93161391e-01, ...,\n",
       "          1.58779180e-01,   7.96371026e-04,   7.83579828e-03],\n",
       "       [  3.29599219e-01,   2.66425031e-02,   6.74758419e-01, ...,\n",
       "          1.58779180e-01,   1.74960989e-03,   4.29068687e-03],\n",
       "       ..., \n",
       "       [  3.29599219e-01,   7.73713594e-02,   6.74758419e-01, ...,\n",
       "          8.74291115e-03,   9.32074981e-03,   4.42488433e-02],\n",
       "       [  3.26086957e-02,   1.28265194e-01,   8.33792228e-01, ...,\n",
       "          2.69376181e-02,   9.97615705e-03,   4.09500490e-02],\n",
       "       [  0.00000000e+00,   6.76177035e-03,   9.43209117e-01, ...,\n",
       "          1.58779180e-01,   3.79684861e-03,   8.50866484e-02]])"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "classifiers = dict()\n",
    "\n",
    "def grid_searcher(clf):\n",
    "    \n",
    "    # PUT IN FUNCTION FOR MINMAXSCALER\n",
    "    \n",
    "    t0 = time()\n",
    "    \n",
    "    even_range = range(2,X.shape[1],2)\n",
    "    random_state = [42]\n",
    "    t_or_f = [True, False]\n",
    "    #powers_of_ten = [10**x for x in range(-5,5)]\n",
    "    logspace = np.logspace(-5, 5, 10)\n",
    "    #kernels = ['linear', 'poly', 'rbf', 'sigmoid']  # takes too long, unfortunately\n",
    "    kernels = ['rbf']\n",
    "    criteria = ['gini', 'entropy']\n",
    "    splitters = ['best', 'random']\n",
    "    max_features = ['auto', 'sqrt', 'log2', None]\n",
    "    inits = ['k-means++', 'random']\n",
    "    \n",
    "    # pca and select K best\n",
    "    pipeline = make_pipeline(RandomizedPCA(), SelectKBest(), clf)\n",
    "    \n",
    "    params = dict(randomizedpca__n_components = even_range,\n",
    "                  randomizedpca__whiten = t_or_f,\n",
    "                  randomizedpca__random_state = random_state,\n",
    "                  selectkbest__k = ['all'])\n",
    "    \n",
    "        \n",
    "    if pipeline.steps[2][0] == 'decisiontreeclassifier':\n",
    "        params['decisiontreeclassifier__criterion'] = criteria\n",
    "        params['decisiontreeclassifier__splitter'] = splitters\n",
    "        params['decisiontreeclassifier__max_features'] = max_features\n",
    "        params['decisiontreeclassifier__random_state'] = random_state\n",
    "    \n",
    "    if pipeline.steps[2][0] == 'svc':\n",
    "        params['svc__C'] = logspace\n",
    "        params['svc__kernel'] = kernels\n",
    "        #params['svc__degree'] = [1,2,3,4,5]  # for use with 'poly'\n",
    "        params['svc__gamma'] = logspace\n",
    "        params['svc__random_state'] = random_state\n",
    "\n",
    "    if pipeline.steps[2][0] == 'kmeans':\n",
    "        params['kmeans__n_clusters'] = [2]\n",
    "        params['kmeans__init'] = inits\n",
    "        params['kmeans__random_state'] = random_state\n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline, param_grid=params, n_jobs=4)\n",
    "\n",
    "    grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print \"*\"*15, pipeline.steps[2][0].upper(), \"*\"*15\n",
    "    #print \"\\nbest estimator: \", grid_search.best_estimator_, \"\\n\" \n",
    "    print \"\\nBEST SCORE: \", grid_search.best_score_, \"\\n\"\n",
    "    #print \"\\nbest params: \", grid_search.best_params_, \"\\n\"\n",
    "\n",
    "    #print \"#\"*50\n",
    "    print \"\\nBEST ESTIMATOR:\"\n",
    "    clf = grid_search.best_estimator_.fit(X_train, y_train)\n",
    "    \n",
    "    #classifiers[pipeline.steps[2][0]] = clf\n",
    "    \n",
    "    X_test_pca = clf.steps[0][1].transform(X_test)\n",
    "    X_test_skb = clf.steps[1][1].transform(X_test_pca) \n",
    "    print \"new X_test shape: \", X_test_skb.shape\n",
    "    \n",
    "    #print \"#\"*50\n",
    "    print \"\\nPREDICTIONS:\"\n",
    "    #test_classifier(clf, my_dataset, features_list)\n",
    "    print \"\\nground truth:\\n\", y_test \n",
    "    \n",
    "    y_pred = clf.steps[2][1].predict(X_test_skb)\n",
    "    print \"\\npredictions:\\n\", y_pred\n",
    "\n",
    "    #print \"#\"*50\n",
    "    print \"\\nEVALUATIONS:\"\n",
    "    print \"\\nconfusion matrix:\\n\", confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print \"\\nclassification report:\\n\", classification_report(y_test, y_pred, target_names=[\"non-poi\", \"poi\"])\n",
    "    \n",
    "    print \"ELAPSED TIME: \", round(time()-t0,3), \"s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Initial Results\n",
    "GaussianNB()  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Accuracy: 0.25560&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Precision: 0.18481&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Recall: 0.79800&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;F1: 0.30011&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;F2: 0.47968  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Total predictions: 10000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;True positives: 1596&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;False positives: 7040&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;False negatives:  404  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;True negatives:  960"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###New Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** GAUSSIANNB ***************\n",
      "\n",
      "BEST SCORE:  0.888888888889 \n",
      "\n",
      "\n",
      "BEST ESTIMATOR:\n",
      "new X_test shape:  (13, 12)\n",
      "\n",
      "PREDICTIONS:\n",
      "\n",
      "ground truth:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "predictions:\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\n",
      "EVALUATIONS:\n",
      "\n",
      "confusion matrix:\n",
      "[[12  1]\n",
      " [ 0  0]]\n",
      "\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    non-poi       1.00      0.92      0.96        13\n",
      "        poi       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.92      0.96        13\n",
      "\n",
      "ELAPSED TIME:  0.273 s\n"
     ]
    }
   ],
   "source": [
    "grid_searcher(GaussianNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** DECISIONTREECLASSIFIER ***************\n",
      "\n",
      "BEST SCORE:  0.863247863248 \n",
      "\n",
      "\n",
      "BEST ESTIMATOR:\n",
      "new X_test shape:  (13, 12)\n",
      "\n",
      "PREDICTIONS:\n",
      "\n",
      "ground truth:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "predictions:\n",
      "[0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
      "\n",
      "EVALUATIONS:\n",
      "\n",
      "confusion matrix:\n",
      "[[10  3]\n",
      " [ 0  0]]\n",
      "\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    non-poi       1.00      0.77      0.87        13\n",
      "        poi       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.77      0.87        13\n",
      "\n",
      "ELAPSED TIME:  2.249 s\n"
     ]
    }
   ],
   "source": [
    "grid_searcher(DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** SVC ***************\n",
      "\n",
      "BEST SCORE:  0.897435897436 \n",
      "\n",
      "\n",
      "BEST ESTIMATOR:\n",
      "new X_test shape:  (13, 2)\n",
      "\n",
      "PREDICTIONS:\n",
      "\n",
      "ground truth:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "predictions:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "EVALUATIONS:\n",
      "\n",
      "confusion matrix:\n",
      "[[13]]\n",
      "\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    non-poi       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       1.00      1.00      1.00        13\n",
      "\n",
      "ELAPSED TIME:  14.182 s\n"
     ]
    }
   ],
   "source": [
    "grid_searcher(SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** KMEANS ***************\n",
      "\n",
      "BEST SCORE:  -4.49750936803 \n",
      "\n",
      "\n",
      "BEST ESTIMATOR:\n",
      "new X_test shape:  (13, 2)\n",
      "\n",
      "PREDICTIONS:\n",
      "\n",
      "ground truth:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "predictions:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "EVALUATIONS:\n",
      "\n",
      "confusion matrix:\n",
      "[[13]]\n",
      "\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    non-poi       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       1.00      1.00      1.00        13\n",
      "\n",
      "ELAPSED TIME:  0.662 s\n"
     ]
    }
   ],
   "source": [
    "grid_searcher(KMeans())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
