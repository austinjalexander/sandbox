{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from imports import *\n",
    "import import_data\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134150, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>50dravg</th>\n",
       "      <th>200dravg</th>\n",
       "      <th>OC%</th>\n",
       "      <th>HL%</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4096</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1093100</td>\n",
       "      <td>0.7780</td>\n",
       "      <td>0.38757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4097</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.52</td>\n",
       "      <td>226000</td>\n",
       "      <td>0.7808</td>\n",
       "      <td>0.38852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4098</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>583300</td>\n",
       "      <td>0.7838</td>\n",
       "      <td>0.38927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.098039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4099</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.56</td>\n",
       "      <td>475900</td>\n",
       "      <td>0.7884</td>\n",
       "      <td>0.39017</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4100</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1537100</td>\n",
       "      <td>0.7928</td>\n",
       "      <td>0.39107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>-0.163934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Open  High   Low  Close   Volume  50dravg  200dravg       OC%    HL%  \\\n",
       "4096  0.52  0.53  0.50   0.52  1093100   0.7780   0.38757  0.000000  0.060   \n",
       "4097  0.52  0.52  0.50   0.52   226000   0.7808   0.38852  0.000000  0.040   \n",
       "4098  0.51  0.52  0.50   0.51   583300   0.7838   0.38927  0.000000  0.040   \n",
       "4099  0.51  0.56  0.50   0.56   475900   0.7884   0.39017  0.098039  0.120   \n",
       "4100  0.57  0.63  0.56   0.57  1537100   0.7928   0.39107  0.000000  0.125   \n",
       "\n",
       "         label  \n",
       "4096  0.000000  \n",
       "4097  0.000000  \n",
       "4098  0.098039  \n",
       "4099  0.000000  \n",
       "4100 -0.163934  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers = [filename[:-4] for filename in os.listdir('quandl_data')]\n",
    "\n",
    "stock_df, prediction_df = import_data.import_data(tickers)\n",
    "print stock_df.shape\n",
    "stock_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134150, 9) (134150, 1)\n"
     ]
    }
   ],
   "source": [
    "y = stock_df['label'].values\n",
    "y = y.reshape(y.shape[0], 1)\n",
    "\n",
    "stock_df = stock_df.drop('label', axis=1)\n",
    "X = stock_df.values\n",
    "\n",
    "print X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_subset = False\n",
    "\n",
    "if get_subset == True:\n",
    "    indices = np.random.choice(X.shape[0], 1000)\n",
    "    X = X[indices,:]\n",
    "    y = y[indices, :]\n",
    "    print X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NN(object):\n",
    "    \n",
    "    def __init__(self, Lambda=0):\n",
    "        \n",
    "        # hyperparameters\n",
    "        self.input_layer_size = 10\n",
    "        self.hidden_layer_size = 10\n",
    "        self.output_layer_size = 1\n",
    "        \n",
    "        # weights\n",
    "        self.W1 = np.random.randn(self.input_layer_size, self.hidden_layer_size)\n",
    "        self.W2 = np.random.randn(self.hidden_layer_size, self.output_layer_size)\n",
    "        \n",
    "        # regularization\n",
    "        self.Lambda = Lambda\n",
    "        \n",
    "    def get_weights(self):\n",
    "        return np.concatenate((self.W1.ravel(), self.W2.ravel()))\n",
    "    \n",
    "    def set_weights(self, weights):\n",
    "        W1_start  = 0\n",
    "        \n",
    "        W1_end = (self.hidden_layer_size * self.input_layer_size)\n",
    "        self.W1 = np.reshape(weights[W1_start:W1_end], (self.input_layer_size,self.hidden_layer_size))\n",
    "        \n",
    "        W2_end = W1_end + (self.hidden_layer_size * self.output_layer_size)\n",
    "        self.W2 = np.reshape(weights[W1_end:W2_end], (self.hidden_layer_size,self.output_layer_size))\n",
    "    \n",
    "    def forward_propagate(self, X):\n",
    "        self.z2 = np.dot(X, self.W1)\n",
    "        self.a2 = self.activation(self.z2) \n",
    "        self.z3 = np.dot(self.a2, self.W2)\n",
    "        y_hat = self.activation(self.z3)\n",
    "        return y_hat\n",
    "    \n",
    "    def activation(self, z):\n",
    "        return np.true_divide(1, (1 + np.exp(-z)))\n",
    "\n",
    "    def visualize_activation(self):\n",
    "        inputs = np.arange(-6,6,0.01)\n",
    "        plt.plot(inputs, self.activation(inputs))\n",
    "        plt.show()\n",
    "        \n",
    "    def activation_prime(self, z):\n",
    "        return np.true_divide(np.exp(-z), ((1 + np.exp(-z))**2))\n",
    "    \n",
    "    def visualize_activation_prime(self):\n",
    "        inputs = np.arange(-6,6,0.01)\n",
    "        plt.plot(inputs, self.activation(inputs))\n",
    "        plt.plot(inputs, self.activation_prime(inputs))\n",
    "        plt.show()\n",
    "        \n",
    "    def cost(self, X, y):\n",
    "        self.y_hat = self.forward_propagate(X)\n",
    "        left = 0.5 * np.sum((y - self.y_hat)**2)/X.shape[0]\n",
    "        right = (self.Lambda/2.0)*(np.sum(self.W1**2) + np.sum(self.W2**2))\n",
    "        return left + right\n",
    "        \n",
    "    def cost_prime(self, X, y):\n",
    "        self.y_hat = self.forward_propagate(X)\n",
    "        \n",
    "        delta3 =  np.multiply(-(y - self.y_hat), self.activation_prime(self.z3))\n",
    "        dJdW2 = np.dot(self.a2.T, delta3)/X.shape[0] + (self.Lambda*self.W2)\n",
    "        \n",
    "        delta2 = np.dot(delta3, self.W2.T) * self.activation_prime(self.z2)\n",
    "        dJdW1 = np.dot(X.T, delta2)/X.shape[0] + (self.Lambda*self.W1)\n",
    "        \n",
    "        return dJdW1, dJdW2\n",
    "                           \n",
    "    def compute_gradient(self, X, y):\n",
    "        dJdW1, dJdW2 = self.cost_prime(X, y)\n",
    "        return np.concatenate((dJdW1.ravel(), dJdW2.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_activation():\n",
    "    nn = NN()\n",
    "    nn.visualize_activation_prime()\n",
    "#test_activation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def testNN():\n",
    "    nn = NN()\n",
    "    y_hat = nn.forward_propagate(X)\n",
    "    print y_hat, \"\\n\"\n",
    "    print y, \"\\n\"\n",
    "    \n",
    "    cost1 = nn.cost(X,y)\n",
    "    print cost1, \"\\n\"\n",
    "\n",
    "    dJdW1, dJdW2 = nn.cost_prime(X,y)\n",
    "    print dJdW1, \"\\n\"\n",
    "    print dJdW2\n",
    "#testNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def estimate_gradient(N, X, y):\n",
    "    weights = N.get_weights()\n",
    "    estimated_gradient = np.zeros(weights.shape)\n",
    "    perturb = np.zeros(weights.shape)\n",
    "    epsilon = 1e-4\n",
    "    \n",
    "    for i in xrange(len(weights)):\n",
    "        perturb[i] = epsilon\n",
    "        \n",
    "        N.set_weights(weights + perturb)\n",
    "        loss2 = N.cost(X,y)\n",
    "        \n",
    "        N.set_weights(weights - perturb)\n",
    "        loss1 = N.cost(X,y)\n",
    "        \n",
    "        estimated_gradient[i] = (loss2 - loss1) / (2 * epsilon)\n",
    "        \n",
    "        perturb[i] = 0\n",
    "    \n",
    "    N.set_weights(weights)\n",
    "        \n",
    "    return estimated_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_gradient_estimation():\n",
    "    nn = NN()\n",
    "    estimated_gradient = estimate_gradient(nn,X,y)\n",
    "    gradient = nn.compute_gradient(X,y)\n",
    "\n",
    "    print estimated_gradient[:3]\n",
    "    print gradient[:3]\n",
    "    print\n",
    "    print np.linalg.norm(gradient-estimated_gradient)/np.linalg.norm(gradient+estimated_gradient)   \n",
    "#test_gradient_estimation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class trainer(object):\n",
    "    \n",
    "    def __init__(self, N):\n",
    "        self.N = N\n",
    "        \n",
    "    def callback(self, weights):\n",
    "        self.N.set_weights(weights)\n",
    "        self.J.append(self.N.cost(self.train_X, self.train_y))\n",
    "        self.test_J.append(self.N.cost(self.test_X, self.test_y))\n",
    "        \n",
    "    def cost_wrapper(self, weights, X, y):\n",
    "        self.N.set_weights(weights)\n",
    "        c = self.N.cost(X, y)\n",
    "        g = self.N.compute_gradient(X,y)\n",
    "        \n",
    "        return c, g\n",
    "    \n",
    "    def set_scale(self, X):\n",
    "        self.scaler = StandardScaler().fit(X)\n",
    "        \n",
    "    def get_scale(self):\n",
    "        return self.scaler\n",
    "    \n",
    "    def add_bias(self, X):\n",
    "        return np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "    \n",
    "    def train(self, X,y):\n",
    "        \n",
    "        train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        self.set_scale(train_X)\n",
    "        scaler = self.get_scale()\n",
    "        \n",
    "        train_X = scaler.transform(train_X)\n",
    "        self.train_X = self.add_bias(train_X)\n",
    "        self.train_y = train_y # StandardScaler().fit_transform(train_y)\n",
    "        \n",
    "        self.test_X = scaler.transform(test_X)\n",
    "        self.test_X = self.add_bias(test_X)\n",
    "        self.test_y = test_y # StandardScaler().fit_transform(test_y)\n",
    "        \n",
    "        self.J = []\n",
    "        self.test_J = []\n",
    "        \n",
    "        weights0 = self.N.get_weights()\n",
    "        \n",
    "        options = {'maxiter':500, 'disp':True}\n",
    "        _res = optimize.minimize(self.cost_wrapper, weights0, jac=True, method='BFGS', args=(self.train_X,self.train_y), options=options, callback=self.callback)\n",
    "        \n",
    "        self.N.set_weights(_res.x)\n",
    "        self.optimization_results = _res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015140\n",
      "         Iterations: 43\n",
      "         Function evaluations: 46\n",
      "         Gradient evaluations: 46\n",
      "\n",
      "time for training: 9.45 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAECCAYAAADq7fyyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10fb685d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time0 = time()\n",
    "\n",
    "nn = NN(Lambda=0.01) # 0.0001\n",
    "Trainer = trainer(nn)\n",
    "Trainer.train(X,y)\n",
    "\n",
    "print \"\\ntime for training:\", np.round((time() - time0),2), \"seconds\"\n",
    "\n",
    "plt.plot(Trainer.J)\n",
    "plt.plot(Trainer.test_J)\n",
    "plt.legend(['J', 'test_J'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 ABIO 0.1\n",
      " 1 ACOR 0.1\n",
      " 2 AERI 0.1\n",
      " 3 AFFX 0.1\n",
      " 4 AGEN 0.1\n",
      " 5 ARIA 0.1\n",
      " 6 ARNA 0.1\n",
      " 7 ARWR 0.1\n",
      " 8 ATNM 0.1\n",
      " 9 AVXL 0.09\n",
      "10 AXDX 0.1\n",
      "11  AXN 0.1\n",
      "12 BABY 0.1\n",
      "13 BCRX 0.1\n",
      "14 BGMD 0.09\n",
      "15 BIIB 0.1\n",
      "16 BLUE 0.1\n",
      "17 BRKR 0.1\n",
      "18 CBMG 0.1\n",
      "19 CBPO 0.1\n",
      "20 CGEN 0.1\n",
      "21 CLDN 0.1\n",
      "22 CLDX 0.1\n",
      "23 COHR 0.1\n",
      "24 CPHD 0.1\n",
      "25 CPRX 0.1\n",
      "26 CRIS 0.1\n",
      "27 CYBX 0.1\n",
      "28 CYNO 0.1\n",
      "29 CYTR 0.1\n",
      "30 DSCO 0.1\n",
      "31 DYAX 0.1\n",
      "32 ECYT 0.1\n",
      "33 ENZN 0.1\n",
      "34 ETRM 0.1\n",
      "35 EXAS 0.1\n",
      "36 EXEL 0.1\n",
      "37 FATE 0.1\n",
      "38 FEIC 0.1\n",
      "39 FLDM 0.1\n",
      "40 GILD 0.1\n",
      "41 GNCA 0.1\n",
      "42 HALO 0.1\n",
      "43 IART 0.1\n",
      "44 IDRA 0.1\n",
      "45 IDXX 0.1\n",
      "46 ILMN 0.1\n",
      "47 IMMU 0.1\n",
      "48 IMRS 0.09\n",
      "49 INCY 0.1\n",
      "50  INO 0.1\n",
      "51 LPCN 0.1\n",
      "52 MEIP 0.09\n",
      "53 MNKD 0.1\n",
      "54 OREX 0.1\n",
      "55 PGNX 0.1\n",
      "56 QLTI 0.1\n",
      "57 RMTI 0.1\n",
      "58 SGYP 0.1\n",
      "59  SYN 0.1\n",
      "60 THLD 0.1\n",
      "61 TNXP 0.1\n",
      "62 TPIV 0.09\n"
     ]
    }
   ],
   "source": [
    "pred_df = prediction_df[prediction_df['label'].apply(np.isnan) == True]\n",
    "pred_tickers = pred_df['ticker'].unique()\n",
    "pred_X = pred_df.drop(['ticker','label'], axis=1).values\n",
    "\n",
    "for i in xrange(pred_X.shape[0]):\n",
    "    scaler = Trainer.get_scale()\n",
    "    x = scaler.transform(pred_X[i:i+1,0:9])\n",
    "    x = Trainer.add_bias(x)\n",
    "    y_hat = nn.forward_propagate(x)\n",
    "    print str(i).rjust(2), str(pred_tickers[i]).rjust(4), np.round(y_hat[0][0],2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
